{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b43c916c-6832-4218-95af-2a1450387d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Boundary01_0001.csv\n",
      "--------------------------------\n",
      "Processed Boundary01_0002.csv\n",
      "--------------------------------\n",
      "Processed Boundary01_0003.csv\n",
      "--------------------------------\n",
      "Processed Boundary01_0004.csv\n",
      "--------------------------------\n",
      "Processed Boundary01_0005.csv\n",
      "--------------------------------\n",
      "Processed Boundary01_0006.csv\n",
      "--------------------------------\n",
      "Processed Boundary01_0007.csv\n",
      "--------------------------------\n",
      "Processed Boundary01_0008.csv\n",
      "--------------------------------\n",
      "All data written to H:\\Shadman\\Isabel_2003_FMModels\\CloseShore_FM_Wave_2003\\BnD_AllForcing\\Merged\\Boundary01.bc\n"
     ]
    }
   ],
   "source": [
    "### It will take in the pli file and make a list of the Boundary points.\n",
    "### This boundary point name will be used to track down the observatio points from the his file.\n",
    "### This will then be printed.\n",
    "### reference time will be given as input.\n",
    "### The timestep will be calculated w.r.t this reference point.\n",
    "### they will be plotted aganist each other. This might not be required if we are extracting the full time scale from the ocean model and the timesapn matches\n",
    "### the intended timestep we are looking to run the main model.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# Directory where the files are stored\n",
    "file_designation=\"Boundary01_\"\n",
    "directory = r'H:\\Shadman\\Isabel_2003_FMModels\\CloseShore_FM_Wave_2003\\BnD_AllForcing\\Merged'\n",
    "output_file_path = os.path.join(directory, \"Boundary01.bc\")\n",
    "\n",
    "\n",
    "# Define the reference time\n",
    "reference_time = dt.datetime.strptime('2001-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Output file for all data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###========================================================================================\n",
    "\n",
    "# Open the output file once and write data for each CSV\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    # Loop over each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith(file_designation) and filename.endswith(\".csv\"):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            \n",
    "            # Load the CSV file\n",
    "            data = pd.read_csv(file_path)\n",
    "            \n",
    "            # Convert date and time column to datetime and calculate seconds from reference time\n",
    "            data['date and time'] = pd.to_datetime(data['date and time'])\n",
    "            data['date and time'] = (data['date and time'] - reference_time).dt.total_seconds().astype(int)\n",
    "            \n",
    "            # Prepare the header content\n",
    "            header_content = f\"\"\"\n",
    "[forcing]\n",
    "Name                            = {filename.split('.')[0]}\n",
    "Function                        = timeseries\n",
    "Time-interpolation              = linear\n",
    "Quantity                        = time\n",
    "Unit                            = seconds since 2001-01-01 00:00:00\n",
    "Quantity                        = waterlevelbnd\n",
    "Unit                            = m\n",
    "\"\"\"\n",
    "            # Write the header and data to the output file\n",
    "            output_file.write(header_content.strip() + \"\\n\")\n",
    "            # Convert dataframe to string format without header and index\n",
    "            data_string = data.to_string(header=False, index=False)\n",
    "            output_file.write(data_string + \"\\n\")\n",
    "            \n",
    "            print(f\"Processed {filename}\")\n",
    "            print('--------------------------------')\n",
    "\n",
    "print(f\"All data written to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba48e0f-8e0e-448a-9797-290070ebdef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa96a6a6-2929-4f5b-9623-60512c7e40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2826bdb-c442-431e-bfbb-938a2add2ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
